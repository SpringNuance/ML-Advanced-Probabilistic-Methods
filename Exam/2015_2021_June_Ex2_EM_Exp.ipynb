{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Q2) EM algorithm\n",
    "Consider N i.i.d. observations $x_n, n = 1,...,N$ from a two-component mixture model of exponential\n",
    "distributions\n",
    "\n",
    "$$p(x_n|\\theta, \\lambda_1, \\lambda_2) = \\theta Exp(x_n|\\lambda_1) + (1 - \\theta) Exp(x_n|\\lambda_2)$$\n",
    "with parameters $(\\theta, \\lambda_1, \\lambda_2)$.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A) Represent the model using latent variables and derive the Q-function of the EM algorithm. (4.5p)\n",
    "\n",
    "We formulate the model using latent variables $z_n = (z_{1},...,z_{N})$ which explicitly specify the component\n",
    "responsible for generating observation $x_n$. In detail,\n",
    "\n",
    "$z_n = (z_{n1}, z_{n2})^T = \n",
    "\\begin{cases} \n",
    "(1,0)^T, & (x_n \\text{ is from } Exp(x_n|\\lambda_1)) \\\\\n",
    "(0,1)^T, & (x_n \\text{ is from } Exp(x_n|\\lambda_2))\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "and place a prior on the latent variables\n",
    "\n",
    "$p(\\mathbf{z}|\\theta) = \\prod^N_{n=1} \\theta^{z_{n1}} (1- \\theta)^{z_{n_2}}$\n",
    "\n",
    "The likelihood in the latent variable model is given by\n",
    "\n",
    "$p(\\mathbf{x}|\\mathbf{z},\\lambda_1,\\lambda_2) = \\prod^N_{n=1} Exp(x_n|\\lambda_1)^{z_{n1}} Exp(x_n|\\lambda_2)^{z_{n2}}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joint distribution of all observed (${\\mathbf{x}}$) and unobserved variables ($\\mathbf{z}, \\theta, \\lambda_1,\\lambda_2$) factorizes as follows\n",
    "\n",
    "$p(\\mathbf{x},\\mathbf{z},\\theta,\\lambda_1,\\lambda_2) = p(\\theta) p(\\lambda_1) p(\\lambda_2) p(\\mathbf{z}|\\theta) p(\\mathbf{x}|\\mathbf{z},\\lambda_1,\\lambda_2)$\n",
    "\n",
    "and the log of the joint distribution can correspondingly be written as\n",
    "\n",
    "$\\log p(\\mathbf{x},\\mathbf{z},\\theta,\\lambda_1,\\lambda_2) = \\log p(\\theta) + \\log p(\\lambda_1) + \\log p(\\lambda_2) + \\log p(\\mathbf{z}|\\theta) + \\log p(\\mathbf{x}|\\mathbf{z},\\lambda_1,\\lambda_2)$\n",
    "\n",
    "We approximate the posterior distribution $p(\\mathbf{z},\\theta,\\lambda_1,\\lambda_2|\\mathbf{x}) $ using the factorized variational distribution $\\lambda(\\mathbf{z}) \\lambda(\\theta) \\lambda(\\lambda_1) \\lambda(\\lambda_2)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive the Q-function of the EM algorithm.\n",
    "\n",
    "The complete data log-likelihood is the joint log likelihood of both the observed variable, $\\mathbf{x}$ and the latent variable, $\\mathbf{z}$. In the EM-algorithm we will maximize the expectation of the log-likelihood\n",
    "of the complete data $(\\mathbf{x}, \\mathbf{z})$. The log-likelihood is:\n",
    "\n",
    "$\\log p(\\mathbf{x}, \\mathbf{z} | \\theta,\\lambda_1,\\lambda_2) = \\log \\left\\{\\prod\\limits^N_{n=1} p(x_n, z_n| \\theta, \\lambda_1,\\lambda_2) \\right\\} = \\sum^N_{n=1} \\log p(x_n, z_n | \\theta, \\lambda_1,\\lambda_2)$\n",
    "\n",
    "=> $\\log p(\\mathbf{x}, \\mathbf{z} | \\theta,\\lambda_1,\\lambda_2) = \\sum^N_{n=1} \\log \\left(p(x_n | z_n, \\lambda_1, \\lambda_2) p(z_n | \\theta)\\right) $\n",
    "\n",
    "=> $\\log p(\\mathbf{x}, \\mathbf{z} | \\theta,\\lambda_1,\\lambda_2) = \\sum^N_{n=1} \\log \\left(\\theta^{z_{n1}} Exp(x_n|\\lambda_1)^{z_{n1}} (1-\\theta)^{z_{n2}} Exp(x_n|\\lambda_2)^{z_{n2}}  \\right)$ (from the prior and likelihood above)\n",
    "\n",
    "=> $\\log p(\\mathbf{x}, \\mathbf{z} | \\theta,\\lambda_1,\\lambda_2) = \\sum^N_{n=1} z_{n1} \\log \\left(\\theta Exp(x_n|\\lambda_1) \\right) + z_{n2} \\log \\left((1-\\theta) Exp(x_n|\\lambda_2) \\right)$\n",
    "\n",
    "=> $\\log p(\\mathbf{x}, \\mathbf{z} | \\theta,\\lambda_1,\\lambda_2) = \\sum^N_{n=1} \\left( z_{n1}\\log \\theta + z_{n1} \\log Exp(x_n|\\lambda_1) + z_{n2} \\log (1-\\theta) + z_{n2} \\log Exp(x_n|\\lambda_2) \\right)$ (E.q 1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E-step $1^0$\n",
    "Compute the posterior distribution of the latent variables, given the current estimate $\\theta^0$ of $\\theta$, $\\lambda_1^0$ of $\\lambda_1$ and $\\lambda_2^0$ of $\\lambda_2$:\n",
    "\n",
    "$p(z_{n1} = 1|x_n,\\theta^0, \\lambda_1^0, \\lambda_2^0) \\propto \\log p(z_{n1} = 1, x_n | \\theta,\\lambda_1,\\lambda_2) = p(z_{n1}=1)p(x_n|z_n,\\theta^0, \\lambda_1^0, \\lambda_2^0) = \\theta^0 Exp(x_n|\\lambda_1^0)$ (E.q 2)\n",
    "\n",
    "$p(z_{n2} = 1|x_n,\\theta^0, \\lambda_1^0, \\lambda_2^0) \\propto \\log p(z_{n1} = 1, x_n | \\theta,\\lambda_1,\\lambda_2) = p(z_{n2}=1)p(x_n|z_n, \\theta^0, \\lambda_1^0, \\lambda_2^0) = (1-\\theta_0) Exp(x_n|\\lambda_2^0) $ (E.q 3)\n",
    "\n",
    "By normalizing these two equations E.q 2 and E.q 3, we get:\n",
    "\n",
    "$ \\gamma(z_{n1}) = p(z_{n1} = 1|x_n,\\theta_0, \\lambda_1^0, \\lambda_2^0) = \\dfrac{\\theta^0 Exp(x_n|\\lambda_1^0)}\n",
    "{\\theta^0 Exp(x_n|\\lambda_1^0) + (1-\\theta_0) Exp(x_n|\\lambda_2^0)}$ (E.q 4)\n",
    "\n",
    "$ \\gamma(z_{n2}) = p(z_{n2} = 1|x_n,\\theta_0, \\lambda_1^0, \\lambda_2^0) = \\dfrac{(1-\\theta^0) Exp(x_n|\\lambda_2^0)}\n",
    "{\\theta^0 Exp(x_n|\\lambda_1^0) + (1-\\theta_0) Exp(x_n|\\lambda_2^0)}$ (E.q 5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E-step $2^0$\n",
    "\n",
    "The Q-function of the EM algorithm is derived by taking the expectation of the complete-data log-likelihood with respect to the posterior distribution of the latent variables. In this case, the complete-data log-likelihood is given by $\\log p(\\mathbf{x},\\mathbf{z},\\theta,\\lambda_1​,\\lambda_2​)$, and the posterior distribution of the latent variables is $p(\\mathbf{z}∣ \\mathbf{x}, \\theta,\\lambda_1​,\\lambda2​)$. Evaluate the expectation of the complete data log-likelihood over the posterior distribution of the latent variables in E.q 4 and E.q 5\n",
    "\n",
    "$\\mathcal{Q}(\\theta, \\lambda_1, \\lambda_2|\\theta^0, \\lambda_1^0, \\lambda_2^0) = E_{z|x,\\theta^0, \\lambda_1^0, \\lambda_2^0} [\\log p(\\mathbf{x},\\mathbf{z}|\\theta, \\lambda_1, \\lambda_2)]$\n",
    "\n",
    "$=> \\mathcal{Q}(\\theta, \\lambda_1, \\lambda_2|\\theta^0, \\lambda_1^0, \\lambda_2^0) =  \\sum^N_{n=1} \\sum^2_{k=1}  [p(\\mathbf{z_{nk}}|\\mathbf{x_n}, \\theta^0, \\lambda_1^0, \\lambda_2^0) \\log p(\\mathbf{x_n},\\mathbf{z_{nk}}|\\theta, \\lambda_1, \\lambda_2) ]$\n",
    "\n",
    "$=> \\mathcal{Q}(\\theta, \\lambda_1, \\lambda_2|\\theta^0, \\lambda_1^0, \\lambda_2^0) = \\\\ \\sum^N_{n=1} [ \n",
    "p(\\mathbf{z_{n1}}|\\mathbf{x_n}, \\theta^0, \\lambda_1^0, \\lambda_2^0) \\log p(\\mathbf{x_n},\\mathbf{z_{n1}}|\\theta, \\lambda_1, \\lambda_2) + \\\\\n",
    "p(\\mathbf{z_{n2}}|\\mathbf{x_n}, \\theta^0, \\lambda_1^0, \\lambda_2^0) \\log p(\\mathbf{x_n},\\mathbf{z_{n2}}|\\theta, \\lambda_1, \\lambda_2)]$\n",
    "\n",
    "$=> \\mathcal{Q}(\\theta, \\lambda_1, \\lambda_2|\\theta^0, \\lambda_1^0, \\lambda_2^0)= \\sum^N_{n=1} \n",
    "\\gamma(z_{n1}) \\log(\\theta Exp(x_n|\\lambda_1)) + \\gamma(z_{n2}) \\log ((1-\\theta) Exp(x_n|\\lambda_2))\n",
    "$\n",
    "\n",
    "$=> \\mathcal{Q}(\\theta, \\lambda_1, \\lambda_2|\\theta^0, \\lambda_1^0, \\lambda_2^0) = \\sum^N_{n=1} \\gamma(z_{n1})\\log(\\theta) + \\gamma(z_{n1}) \\log Exp(x_n|\\lambda_1) + \\gamma(z_{n2}) \\log (1-\\theta) + \\gamma(z_{n2}) \\log Exp(x_n|\\lambda_2)$ (answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) Derive the M step update for the $\\lambda_1$ parameter (1.5p)\n",
    "\n",
    "Maximizing for $\\theta_1$:\n",
    "\n",
    "$\\dfrac{d}{d\\theta} \\mathcal{Q}(\\theta; \\theta_0) = \\dfrac{d}{d\\theta} \\sum^N_{n=1} \\gamma(z_{n1})\\log(\\theta) + \\gamma(z_{n1}) \\log Exp(x_n|\\lambda_1) + \\gamma(z_{n2}) \\log (1-\\theta) + \\gamma(z_{n2}) \\log Exp(x_n|\\lambda_2)$\n",
    "\n",
    "$\\dfrac{d}{d\\theta} \\mathcal{Q}(\\theta; \\theta_0) = \\sum^N_{n=1} \\dfrac{\\gamma(z_{n1})}{\\theta} + 0 - \\dfrac{\\gamma(z_{n2})}{1-\\theta} + 0  = \\sum^N_{n=1} \\dfrac{\\gamma(z_{n1})}{\\theta} - \\dfrac{\\gamma(z_{n2})}{1-\\theta} = \\dfrac{N_1}{\\theta} - \\dfrac{N_2}{1-\\theta} $\n",
    "\n",
    "where we have defined $N_2 = \\sum^N_{n=1} \\gamma(z_{n2})$; which can be interpreted as the\n",
    "effective number of observations assigned to the component 2. Similarly, we can also define  $N_1 = \\sum^N_{n=1} \\gamma(z_{n1})$ for the first component\n",
    "\n",
    "Setting $\\dfrac{d}{d\\theta} \\mathcal{Q}(\\theta; \\theta_0) = 0$, we get the result for $\\theta$ \n",
    "\n",
    "$$ \\dfrac{N_1}{\\theta} - \\dfrac{N_2}{1-\\theta} = 0 => \\theta = \\dfrac{N_1}{N_1+N_2} \\text{ (answer)}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximizing for $\\lambda_1$:\n",
    "\n",
    "$\\dfrac{d}{d\\lambda_1} \\mathcal{Q}(\\lambda_1; \\lambda_1^0) = \\dfrac{d}{d\\lambda_1} \\sum^N_{n=1} \\gamma(z_{n1})\\log(\\theta) + \\gamma(z_{n1}) \\log Exp(x_n|\\lambda_1) + \\gamma(z_{n2}) \\log (1-\\theta) + \\gamma(z_{n2}) \\log Exp(x_n|\\lambda_2)$\n",
    "\n",
    "First we need to calculate the derivative of the exponential distribution with respect to $\\lambda_1$:\n",
    "\n",
    "$\\dfrac{d}{d\\lambda_1} Exp(x_n|\\lambda_1) = \\dfrac{d}{d\\lambda_1} (\\lambda_1 \\exp(-\\lambda_1 x_n)) = \\exp(-\\lambda_1 x_n)(1- \\lambda_1 x_n)$\n",
    "\n",
    "=> $\\dfrac{d}{d\\lambda_1} \\log Exp(x_n|\\lambda_1) = \\dfrac{1}{Exp(x_n|\\lambda_1)}\\exp(-\\lambda_1 x_n)(1- \\lambda_1 x_n) = \\dfrac{\\exp(-\\lambda_1 x_n)(1- \\lambda_1 x_n)}{\\lambda_1 \\exp(-\\lambda_1 x_n)} = \\dfrac{1}{\\lambda_1} - x_n$\n",
    "\n",
    "Plugging in the main derivative equation:\n",
    "\n",
    "$\\dfrac{d}{d\\lambda_1} \\mathcal{Q}(\\lambda_1; \\lambda_1^0) = \\sum^N_{n=1} 0 + 0 + \\gamma(z_{n1})(\\dfrac{1}{\\lambda_1} - x_n) + 0 = \\sum^N_{n=1} \\gamma(z_{n1})(\\dfrac{1}{\\lambda_1} - x_n) $\n",
    "\n",
    "Setting $\\dfrac{d}{d\\lambda_1} \\mathcal{Q}(\\lambda_1; \\lambda_1^0) = 0$, we get the result for $\\lambda_1$ \n",
    "\n",
    "$$ \\sum^N_{n=1} \\gamma(z_{n1})(\\dfrac{1}{\\lambda_1} - x_n) = 0 => \\sum^N_{n=1} \\left[\\dfrac{\\gamma(z_{n1})}{\\lambda_1} - \\gamma(z_{n1}) x_n \\right] = 0 => \\lambda_1 = \\dfrac{N_1}{ \\sum^N_{n=1} \\gamma(z_{n1}) x_n } \\text{ (answer)}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) (2015) Learn the maximum likelihood estimates of the parameters $(\\theta, \\lambda_1, \\lambda_2)$\n",
    "\n",
    "Solve similarly to part (b) for $\\theta$ and $\\lambda_2$."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
