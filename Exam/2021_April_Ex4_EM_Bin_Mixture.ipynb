{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Q4) EM algorithm\n",
    "\n",
    "Consider N observations $x_n, n = 1,...,N$ from a two-component mixture of binomial distributions\n",
    "\n",
    "$$p(x_n | \\theta, q_1, q_2) = \\theta Bin(x_n | q_1) + (1 - \\theta) Bin(x_n | q_2)$$\n",
    "\n",
    "(A) Represent the model using latent variables and derive the E step of the expectation maximization. In the\n",
    "end, simplify the Q-function, $\\mathcal{Q}(\\theta, q_1, q_2|\\theta^0, q_1^0, q_2^0)$, where $\\theta^0$, $q_1^0$, $q_2^0$ are the current values of the parameters (4p)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We formulate the model using latent variables $z_n = (z_{1},...,z_{N})$ which explicitly specify the component\n",
    "responsible for generating observation $x_n$. In detail,\n",
    "\n",
    "$z_n = (z_{n1}, z_{n2})^T = \n",
    "\\begin{cases} \n",
    "(1,0)^T, & (x_n \\text{ is from } Bin(x_n | q_1)) \\\\\n",
    "(0,1)^T, & (x_n \\text{ is from } Bin(x_n | q_2))\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "and place a prior on the latent variables\n",
    "\n",
    "$p(\\mathbf{z}|\\theta) = \\prod^N_{n=1} \\theta^{z_{n1}} (1- \\theta)^{z_{n_2}}$\n",
    "\n",
    "The likelihood in the latent variable model is given by\n",
    "\n",
    "$p(\\mathbf{x}|\\mathbf{z},q_1,q_2) = \\prod^N_{n=1} Bin(x_n|q_1)^{z_{n1}} Bin(x_n|q_2)^{z_{n2}}$\n",
    "\n",
    "The joint distribution of all observed (${\\mathbf{x}}$) and unobserved variables ($\\mathbf{z}, \\theta, q_1,q_2$) factorizes as follows\n",
    "\n",
    "$p(\\mathbf{x},\\mathbf{z},\\theta,q_1,q_2) = p(\\theta) p(q_1) p(q_2) p(\\mathbf{z}|\\theta) p(\\mathbf{x}|\\mathbf{z},q_1,q_2)$\n",
    "\n",
    "and the log of the joint distribution can correspondingly be written as\n",
    "\n",
    "$\\log p(\\mathbf{x},\\mathbf{z},\\theta,q_1,q_2) = \\log p(\\theta) + \\log p(q_1) + \\log p(q_2) + \\log p(\\mathbf{z}|\\theta) + \\log p(\\mathbf{x}|\\mathbf{z},q_1,q_2)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complete data log-likelihood is the joint log likelihood of both the observed variable, $\\mathbf{x}$ and the latent variable, $\\mathbf{z}$. In the EM-algorithm we will maximize the expectation of the log-likelihood\n",
    "of the complete data $(\\mathbf{x}, \\mathbf{z})$. The log-likelihood is:\n",
    "\n",
    "$\\log p(\\mathbf{x}, \\mathbf{z} | \\theta,q_1,q_2) = \\log \\left\\{\\prod\\limits^N_{n=1} p(x_n, z_n| \\theta, q_1,q_2) \\right\\} = \\sum^N_{n=1} \\log p(x_n, z_n | \\theta, q_1,q_2)$\n",
    "\n",
    "=> $\\log p(\\mathbf{x}, \\mathbf{z} | \\theta,q_1,q_2) = \\sum^N_{n=1} \\log \\left(p(x_n | z_n, q_1, q_2) p(z_n | \\theta)\\right) $\n",
    "\n",
    "=> $\\log p(\\mathbf{x}, \\mathbf{z} | \\theta,q_1,q_2) = \\sum^N_{n=1} \\log \\left(\\theta^{z_{n1}} Bin(x_n|q_1)^{z_{n1}} (1-\\theta)^{z_{n2}} Bin(x_n|q_2)^{z_{n2}}  \\right)$\n",
    "\n",
    "=> $\\log p(\\mathbf{x}, \\mathbf{z} | \\theta,q_1,q_2) = \\sum^N_{n=1} z_{n1} \\log \\left(\\theta Bin(x_n|q_1) \\right) + z_{n2} \\log \\left((1-\\theta) Bin(x_n|q_2) \\right)$\n",
    "\n",
    "=> $\\log p(\\mathbf{x}, \\mathbf{z} | \\theta,q_1,q_2) = \\sum^N_{n=1} \\left( z_{n1}\\log \\theta + z_{n1} \\log Bin(x_n|q_1) + z_{n2} \\log (1-\\theta) + z_{n2} \\log Bin(x_n|q_2) \\right)$ (E.q 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E-step $1^0$\n",
    "Compute the posterior distribution of the latent variables, given the current estimate $\\theta^0$ of $\\theta$, $q_1^0$ of $q_1$ and $q_2^0$ of $q_2$:\n",
    "\n",
    "$p(z_{n1} = 1|x_n,\\theta^0, q_1^0, q_2^0) \\propto \\log p(z_{n1} = 1, x_n | \\theta,q_1,q_2) = p(z_{n1}=1)p(x_n|z_n,\\theta^0, q_1^0, q_2^0) = \\theta^0 Bin(x_n|q_1^0)$ (E.q 2)\n",
    "\n",
    "$p(z_{n2} = 1|x_n,\\theta^0, q_1^0, q_2^0) \\propto \\log p(z_{n1} = 1, x_n | \\theta,q_1,q_2) = p(z_{n2}=1)p(x_n|z_n, \\theta^0, q_1^0, q_2^0) = (1-\\theta_0) Bin(x_n|q_2^0) $ (E.q 3)\n",
    "\n",
    "By normalizing these two equations E.q 2 and E.q 3, we get:\n",
    "\n",
    "$ \\gamma(z_{n1}) = p(z_{n1} = 1|x_n,\\theta_0, q_1^0, q_2^0) = \\dfrac{\\theta^0 Bin(x_n|q_1^0)}\n",
    "{\\theta^0 Bin(x_n|q_1^0) + (1-\\theta_0) Bin(x_n|q_2^0)}$ (E.q 4)\n",
    "\n",
    "$ \\gamma(z_{n2}) = p(z_{n2} = 1|x_n,\\theta_0, q_1^0, q_2^0) = \\dfrac{(1-\\theta^0) Bin(x_n|q_2^0)}\n",
    "{\\theta^0 Bin(x_n|q_1^0) + (1-\\theta_0) Bin(x_n|q_2^0)}$ (E.q 5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E-step $2^0$\n",
    "Evaluate the expectation of the complete data log-likelihood over the posterior distribution of the latent variables in E.q 4 and E.q 5\n",
    "\n",
    "$\\mathcal{Q}(\\theta, q_1, q_2|\\theta^0, q_1^0, q_2^0) = E_{z|x,\\theta^0, q_1^0, q_2^0} [\\log p(\\mathbf{x},\\mathbf{z}|\\theta, q_1, q_2)]$\n",
    "\n",
    "$=> \\mathcal{Q}(\\theta, q_1, q_2|\\theta^0, q_1^0, q_2^0) =  \\sum^N_{n=1} \\sum^2_{k=1}  [p(\\mathbf{z_{nk}}|\\mathbf{x_n}, \\theta^0, q_1^0, q_2^0) \\log p(\\mathbf{x_n},\\mathbf{z_{nk}}|\\theta, q_1, q_2) ]$\n",
    "\n",
    "$=> \\mathcal{Q}(\\theta, q_1, q_2|\\theta^0, q_1^0, q_2^0) = \\\\ \\sum^N_{n=1} [ \n",
    "p(\\mathbf{z_{n1}}|\\mathbf{x_n}, \\theta^0, q_1^0, q_2^0) \\log p(\\mathbf{x_n},\\mathbf{z_{n1}}|\\theta, q_1, q_2) + \\\\\n",
    "p(\\mathbf{z_{n2}}|\\mathbf{x_n}, \\theta^0, q_1^0, q_2^0) \\log p(\\mathbf{x_n},\\mathbf{z_{n2}}|\\theta, q_1, q_2)]$\n",
    "\n",
    "$=> \\mathcal{Q}(\\theta, q_1, q_2|\\theta^0, q_1^0, q_2^0)= \\sum^N_{n=1} \n",
    "\\gamma(z_{n1}) \\log(\\theta Bin(x_n|q_1)) + \\gamma(z_{n2}) \\log ((1-\\theta) Bin(x_n|q_2))\n",
    "$\n",
    "\n",
    "$=> \\mathcal{Q}(\\theta, q_1, q_2|\\theta^0, q_1^0, q_2^0) = \\sum^N_{n=1} \\gamma(z_{n1})\\log(\\theta) + \\gamma(z_{n1}) \\log Bin(x_n|q_1) + \\gamma(z_{n2}) \\log (1-\\theta) + \\gamma(z_{n2}) \\log Bin(x_n|q_2)$ (answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) Derive the M-step for the $\\theta$ parameter. (2p)\n",
    "\n",
    "The binomial distribution has a probability mass function of the form\n",
    "\n",
    "$$ f(k|m, q) = p(x_n = k) = {m \\choose k} q^k (1-q)^{m-k} $$\n",
    "\n",
    "where $0 \\leq k \\leq m$ is an integer. You can treat m as a known constant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M-step\n",
    "\n",
    "Maximize $\\mathcal{Q}(\\theta, q_1, q_2|\\theta^0, q_1^0, q_2^0)$ with respect to $\\theta$, $q_1$ and $q_2$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximizing for $\\theta$:\n",
    "\n",
    "$\\dfrac{d}{d\\theta} \\mathcal{Q}(\\theta; \\theta_0) = \\dfrac{d}{d\\theta} \\sum^N_{n=1} \\gamma(z_{n1})\\log(\\theta) + \\gamma(z_{n1}) \\log Bin(x_n|q_1) + \\gamma(z_{n2}) \\log (1-\\theta) + \\gamma(z_{n2}) \\log Bin(x_n|q_2)$\n",
    "\n",
    "$\\dfrac{d}{d\\theta} \\mathcal{Q}(\\theta; \\theta_0) = \\sum^N_{n=1} \\dfrac{\\gamma(z_{n1})}{\\theta} + 0 - \\dfrac{\\gamma(z_{n2})}{1-\\theta} + 0  = \\sum^N_{n=1} \\dfrac{\\gamma(z_{n1})}{\\theta} - \\dfrac{\\gamma(z_{n2})}{1-\\theta} = \\dfrac{N_1}{\\theta} - \\dfrac{N_2}{1-\\theta} $\n",
    "\n",
    "where we have defined $N_2 = \\sum^N_{n=1} \\gamma(z_{n2})$; which can be interpreted as the\n",
    "effective number of observations assigned to the component 2. Similarly, we can also define  $N_1 = \\sum^N_{n=1} \\gamma(z_{n1})$ for the first component\n",
    "\n",
    "Setting $\\dfrac{d}{d\\theta} \\mathcal{Q}(\\theta; \\theta_0) = 0$, we get the result for $\\theta$ \n",
    "\n",
    "$$ \\dfrac{N_1}{\\theta} - \\dfrac{N_2}{1-\\theta} = 0 => \\theta = \\dfrac{N_1}{N_1+N_2} \\text{ (answer)}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
