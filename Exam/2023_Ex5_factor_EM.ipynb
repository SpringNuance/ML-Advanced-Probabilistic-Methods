{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Q5) EM algorithm\n",
    "\n",
    "Consider a simple factor analysis model:\n",
    "\n",
    "$$ v_n \\sim N_2(\\mathbf{a} h_n; \\lambda^{-1} I), n = 1,...,N $$\n",
    "$$ h_n \\sim N(0, 1), n = 1,...,N $$\n",
    "\n",
    "where $v_n \\in R^2$ and $h_n \\in R$ for all $n = 1,...,N$. Parameters of the model are the loading matrix (a vector in this case), $\\mathbf{a} \\in R^2$, and precision (inverse variance) $\\lambda^2 \\in R$.\n",
    "\n",
    "(A) Derive and simplify the complete data log-likelihood. (2p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) It can be shown that the posterior distribution $p(h_n|v_n; a_0; \\lambda_0)$, where $w_0; \\lambda_0$ are current estimates of the parameters, is a Gaussian $\\mathcal{N}(h_n|\\mu_n; \\lambda_z^{-1})$ with certain $\\mu_n$ and $\\lambda_z$. Derive formulas for $\\mu_n$ and $\\sigma_z$. (2p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) Derive the Q function needed in the E step of the EM algorithm, and express it using $\\mu_n$ and $\\lambda_z$ (2p)\n",
    "\n",
    "Hint 1: You can solve C even if you did not solve B because the solution to C can be given using $\\mu_n$ and $\\lambda_z$.\n",
    "\n",
    "Hint 2: Completing the square.\n",
    "\n",
    "Hint 3: $Var(X) = E(X^2) - E(X)^2$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
